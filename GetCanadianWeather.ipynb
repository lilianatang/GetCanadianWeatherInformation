{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbaab475-3a70-444c-83d6-c9ac10f55c17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88b9e154-6cbd-4922-a7e1-9cb463ae2273",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import time\n",
    "from geopy.geocoders import Nominatim\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INPUT_FILE = \"New_Query_2025_12_09_3_08pm.csv\" # file that stores all the cities of interest, could be a table too\n",
    "OUTPUT_FILE = \"verified_stations_with_data.csv\"\n",
    "START_YEAR = 1990\n",
    "END_YEAR = 2025\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS main.ext.weather\") # creating the table that holds all the weather information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d73120ea-e9f1-4c81-bd84-39dfb57eea85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"Calculate distance (km) between two points.\"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    return c * 6371"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0d5adda-df66-4f47-bd20-1e461c947f3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_station_inventory():\n",
    "    print(\"Downloading Station Inventory...\")\n",
    "    url = \"https://collaboration.cmc.ec.gc.ca/cmc/climate/Get_More_Data_Plus_de_donnees/Station%20Inventory%20EN.csv\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        return pd.read_csv(io.StringIO(r.content.decode('utf-8', errors='ignore')), skiprows=3)\n",
    "    except Exception as e:\n",
    "        print(f\"Inventory Download Failed: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f92b7c0c-734f-4d09-8d48-48b6bf8bc8ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_sample_temp(station_id, test_year):\n",
    "    \"\"\"\n",
    "    Downloads data for a test year and returns a sample valid temperature.\n",
    "    Returns: (is_valid, sample_text)\n",
    "    \"\"\"\n",
    "    base_url = \"https://climate.weather.gc.ca/climate_data/bulk_data_e.html\"\n",
    "    params = {\n",
    "        'format': 'csv', \n",
    "        'stationID': station_id, \n",
    "        'Year': test_year, \n",
    "        'Month': 1, 'Day': 1, \n",
    "        'timeframe': 2, \n",
    "        'submit': 'Download Data'\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(base_url, params=params, timeout=10)\n",
    "        content = r.content.decode('utf-8')\n",
    "        \n",
    "        # Dynamic Header Detection\n",
    "        lines = content.split('\\n')\n",
    "        skip_rows = 0\n",
    "        for i, line in enumerate(lines):\n",
    "            if \"Date/Time\" in line:\n",
    "                skip_rows = i\n",
    "                break\n",
    "        \n",
    "        if skip_rows == 0 and \"Date/Time\" not in lines[0]:\n",
    "            return False, \"Format Error\"\n",
    "\n",
    "        df = pd.read_csv(io.StringIO(content), skiprows=skip_rows)\n",
    "        \n",
    "        # Check for Max Temp column\n",
    "        max_temp_col = next((c for c in df.columns if \"Max Temp\" in c), None)\n",
    "        # Check for Min Temp column\n",
    "        min_temp_col = next((c for c in df.columns if \"Min Temp\" in c), None)\n",
    "        \n",
    "        if max_temp_col:\n",
    "            # Drop Nulls and get a sample\n",
    "            valid_data = df.dropna(subset=[max_temp_col])\n",
    "            #print(\"Printing Valid Data\")\n",
    "            #print(valid_data)\n",
    "            count = len(valid_data)\n",
    "            all_values =[]\n",
    "            if not valid_data.empty:\n",
    "                #print(\"Counting\")\n",
    "                #print(valid_data)\n",
    "                # Pick a random valid row to display\n",
    "                example = valid_data.iloc[0]\n",
    "                example_date = example['Date/Time']\n",
    "                max_temp = float(example[max_temp_col])\n",
    "                i = 0\n",
    "                for i in range(count):\n",
    "                    sample = valid_data.iloc[i]\n",
    "                    date = sample['Date/Time']\n",
    "                    max_temp = float(sample[max_temp_col])\n",
    "                    min_temp = float(sample[min_temp_col])\n",
    "                    all_values.append({\n",
    "                            \"Station_ID\": station_id,\n",
    "                            \"Date\": date,\n",
    "                            \"Max_Temp\": max_temp,\n",
    "                            \"Min_Temp\": min_temp\n",
    "                        })\n",
    "                    i = i + 1\n",
    "                #print(\"Printing next data point\")\n",
    "                #print(valid_data.iloc[1])\n",
    "                return True, all_values, max_temp, example_date\n",
    "            else:\n",
    "                return False, None, None, None\n",
    "        else:\n",
    "            return False, None, None, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        return False, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa24cdef-9117-458f-8109-8929a9637b25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def find_verified_station(lat, lon, inventory_df):\n",
    "    \"\"\"\n",
    "    Finds nearest station and VERIFIES it has temperature data by looking it up.\n",
    "    \"\"\"\n",
    "    if pd.isna(lat) or pd.isna(lon): return None, None, \"No Coords\", 0\n",
    "\n",
    "    # Filter for active years\n",
    "    inv = inventory_df.copy()\n",
    "    inv['DLY First Year'] = pd.to_numeric(inv['DLY First Year'], errors='coerce')\n",
    "    inv['DLY Last Year'] = pd.to_numeric(inv['DLY Last Year'], errors='coerce')\n",
    "    \n",
    "    candidates = inv[\n",
    "        (inv['DLY Last Year'] >= START_YEAR) & \n",
    "        (inv['DLY First Year'] <= END_YEAR)\n",
    "    ].copy()\n",
    "\n",
    "    if candidates.empty: return None, None, \"No Active Stations\", 0\n",
    "\n",
    "    # Calculate distance\n",
    "    lat_col = [c for c in inv.columns if \"Latitude\" in c][0]\n",
    "    lon_col = [c for c in inv.columns if \"Longitude\" in c][0]\n",
    "    candidates['distance'] = candidates.apply(\n",
    "        lambda row: haversine(lon, lat, row[lon_col], row[lat_col]), axis=1\n",
    "    )\n",
    "    candidates = candidates.sort_values('distance')\n",
    "    \n",
    "    # Check top 5 closest stations\n",
    "    for index, row in candidates.iloc[:5].iterrows():\n",
    "        st_id = row['Station ID']\n",
    "        st_name = row['Name']\n",
    "        \n",
    "        # Pick a test year (middle of our range or last active year)\n",
    "        test_year = int((START_YEAR + END_YEAR) / 2)\n",
    "        if test_year > row['DLY Last Year']: test_year = int(row['DLY Last Year'])\n",
    "        \n",
    "        # PROBE THE DATA\n",
    "        is_valid, results, sample_text, sample_date = get_sample_temp(st_id, test_year)\n",
    "        #print(\"Printing getting sample\")\n",
    "        #print(get_sample_temp(st_id, test_year))\n",
    "        if is_valid:\n",
    "            #print(results)\n",
    "            return st_id, st_name, sample_text, sample_date, row['distance'], results\n",
    "        else:\n",
    "            # print(f\"    x Skipped {st_name} (ID: {st_id}) - {sample_text}\")\n",
    "            time.sleep(0.2)\n",
    "\n",
    "    return None, None, None, None, 0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb5f665a-ef52-4523-bc02-533bfd5f12b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- MAIN EXECUTION ---\n",
    "if __name__ == \"__main__\":\n",
    "    df_locs = spark.sql(\"select distinct County from main.silver_raw.monthlymarketshare_details\").toPandas()\n",
    "    inventory = get_station_inventory()\n",
    "    geolocator = Nominatim(user_agent=\"weather_display_v3\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for year in range(START_YEAR, END_YEAR + 1):\n",
    "        for idx, row in df_locs.iterrows():\n",
    "            loc_name = row['County']\n",
    "            \n",
    "            try:\n",
    "                # 1. Geocode\n",
    "                loc = geolocator.geocode(f\"{loc_name}, Canada\", timeout=10)\n",
    "                if loc:\n",
    "                    # 2. Find & Verify\n",
    "                    st_id, st_name, sample, date, dist, final_results = find_verified_station(loc.latitude, loc.longitude, inventory)\n",
    "                    #print(st_id)\n",
    "                    if st_id:\n",
    "                        i = 0\n",
    "                        for i in range(len(final_results)):\n",
    "                            results.append({\n",
    "                                \"Original_Location\": loc_name,\n",
    "                                \"Station_ID\": st_id,\n",
    "                                \"Station_Name\": st_name,\n",
    "                                \"Max_Temp\": final_results[i]['Max_Temp'],\n",
    "                                \"Min_Temp\": final_results[i]['Min_Temp'],\n",
    "                                \"Date\": final_results[i]['Date']                                \n",
    "                                })\n",
    "                            results_df = pd.DataFrame(results)\n",
    "                            spark_df = spark.createDataFrame(results_df)\n",
    "                            spark_df.write.format(\"delta\") \\\n",
    "                                    .mode(\"append\") \\\n",
    "                                    .option(\"mergeSchema\", \"true\") \\\n",
    "                                    .saveAsTable(\"main.ext.weather\")\n",
    "                            i = i + 1\n",
    "                    else:\n",
    "                        print(f\"{loc_name[:30]:<30} | {'No Match':<25} | -          | {sample}\")\n",
    "                else:\n",
    "                    print(f\"{loc_name[:30]:<30} | {'Geo Failed':<25} | -          | -\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {loc_name}: {e}\")\n",
    "            \n",
    "            # Rate limit\n",
    "            time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "GetCanadianWeather",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
